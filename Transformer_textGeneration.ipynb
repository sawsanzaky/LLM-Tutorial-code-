{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSnhqTk91IiNNliOeMCsA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sawsanzaky/LLM-Tutorial-code-/blob/main/Transformer_textGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-RtHuV1ZZIa",
        "outputId": "ed0f2da0-1b17-45de-adde-830dfbe6541b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a brave knight... a friend of the goddess. So we were on a date, you see. That was when I had to come to try something. I made my way to my bed, naked, still so\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation pipeline\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "\n",
        "# Prompt the LLM with a starting sentence\n",
        "prompt = \"Once upon a time, there was a brave knight...\"\n",
        "\n",
        "# Generate text based on the prompt\n",
        "generated_text = text_generator(prompt)\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GSTCvBNbxAh",
        "outputId": "5974b01b-0972-4bdc-c928-8e295d15746e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a brave knight... a friend of the goddess. So we were on a date, you see. That was when I had to come to try something. I made my way to my bed, naked, still so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".................................................................................................................................................................................................................................\n"
      ],
      "metadata": {
        "id": "AN3Rd-_3c2q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hereâ€™s a Python code example demonstrating sentiment analysis using the Transformers library:**"
      ],
      "metadata": {
        "id": "MJRaSR7sdXPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Analyze the sentiment of a few sentences\n",
        "sentences = [\n",
        "    \"This movie is absolutely fantastic! I loved it.\",\n",
        "    \"The food was disappointing. It was bland and overpriced.\",\n",
        "    \"This book is a must-read for anyone interested in history.\",\n",
        "    \"The service at this hotel was terrible. I wouldn't stay here again.\",\n",
        "    \" i can't make anything , am poor\",\n",
        "    \" i love hazam , but he love me 50 %\"\n",
        "]\n",
        "\n",
        "# Analyze the sentiment of each sentence\n",
        "for sentence in sentences:\n",
        "    sentiment = sentiment_analyzer(sentence)[0]\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Sentiment: {sentiment['label']} ({sentiment['score']:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7k_9o29cEZp",
        "outputId": "92d79748-8e62-42a6-e40a-7343def800d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: This movie is absolutely fantastic! I loved it.\n",
            "Sentiment: POSITIVE (1.00)\n",
            "Sentence: The food was disappointing. It was bland and overpriced.\n",
            "Sentiment: NEGATIVE (1.00)\n",
            "Sentence: This book is a must-read for anyone interested in history.\n",
            "Sentiment: POSITIVE (1.00)\n",
            "Sentence: The service at this hotel was terrible. I wouldn't stay here again.\n",
            "Sentiment: NEGATIVE (1.00)\n",
            "Sentence:  i can't make anything , am poor\n",
            "Sentiment: NEGATIVE (1.00)\n",
            "Sentence:  i love hazam , but he love me 50 %\n",
            "Sentiment: POSITIVE (1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "......>>>> Explanation:\n",
        "\n",
        "Import the pipeline: The pipeline function from the transformers library loads a pre-trained LLM model for sentiment analysis.\n",
        "Initialize the pipeline: The sentiment-analysis pipeline is specifically designed for sentiment classification.\n",
        "Prepare sentences: A list of sample sentences is created for analysis.\n",
        "Analyze sentiment: The sentiment_analyzer function takes each sentence as input and returns a dictionary containing:\n",
        "label: The predicted sentiment label (e.g., \"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\")\n",
        "score: A numerical score representing the confidence in the prediction (ranges from 0 to 1)\n",
        "5. Print results: The code prints both the sentence and its corresponding sentiment analysis for clarity."
      ],
      "metadata": {
        "id": "djqebPqpd9yU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "......>>>>>Key points:\n",
        "\n",
        "The LLM model handles understanding the nuances of language and classifying sentiment.\n",
        "The code demonstrates how to easily leverage this ability for practical tasks.\n",
        "Sentiment analysis has wide-ranging applications, including social media analysis, customer feedback analysis, and product reviews."
      ],
      "metadata": {
        "id": "PnZi7l0KeqQL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4nLgnEGc-Xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}